{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа с таблицами в pandas\n",
    "\n",
    "## Вступление\n",
    "Сегодня мы начнём работать с табличными данными в питоне, и в этом нам поможет библиотека pandas. Pandas — это самый популярный инструмент для работы с данными. Цель семинара — познакомить вас с основными конструкциями pandas и научить им пользоваться.\n",
    "\n",
    "Почему pandas удобный?\n",
    "1.\tУдобное представление таблиц и куча готовых методов, как работать с этими таблицами\n",
    "2.\tПростота использования\n",
    "3.\tНаличие встроенных визуализаций\n",
    "4.\tНаличие всех функций из excel (и даже больше)\n",
    "5.\tУниверсальность инструмента, можно читать почти все табличные типы данных\n",
    "6.\tХорошо подходит для экспериментов с данными\n",
    "\n",
    "А почему он неудобный?\n",
    "1.\tМедленный\n",
    "2.\tЧаще всего нельзя использовать в проде из-за скорости\n",
    "3.\tИногда сложно интерпретировать код, написанный на pandas\n",
    "\n",
    "### План семинара\n",
    "1. Работаем с датасетом оценок студентов\n",
    "2. Работаем с датасетом пассажиров Титаника\n",
    "\n",
    "### Дополнительные материалы\n",
    "\n",
    "[Pandas Cheat Sheet](https://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf)\n",
    "\n",
    "[10 Minutes To Pandas](https://pandas.pydata.org/pandas-docs/stable/10min.html)\n",
    "\n",
    "[Pandas CookBook](https://pandas.pydata.org/pandas-docs/stable/cookbook.html#cookbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Работаем с датасетом оценок студентов\n",
    "\n",
    "По ссылкам можно скачать [датасет с оценками](https://disk.yandex.ru/d/86NPUWOVSS13og) и [таблицу с именами и фамилиями](https://disk.yandex.ru/i/lnIGVynCo-0nrA)\n",
    "\n",
    "Pandas предоставляет нам много различных инструментов работы с табличными данными. Главные из них — это: класс таблицы `pandas.core.frame.DataFrame` и его методы; класс серии данных (например, столбец таблицы) `pandas.core.series.Series` и его методы; и различные функции библиотеки. \n",
    "\n",
    "Начнём с подгрузки таблицы из файла и посмотрим на методы класса `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"grades.csv\", sep=\",\", index_col=0)\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# размер таблицы\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вывести начало таблицы\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вывести конец таблицы\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбрать случайные строки\n",
    "df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбрать случайные строки 2\n",
    "df.sample(frac=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим работу со столбцами: датафрейм можно индексировать квадратными скобками с названиями столбцов. Столбец будет экземпляром класса `pandas.core.series.Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col0 = df[\"0\"]\n",
    "col0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(col0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбрать 5 строк с наибольшими значениями в столбцах '3', '4'\n",
    "df.nlargest(n=5, columns=[\"3\", \"4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подсчитать количество уникальных значений в столбце 3\n",
    "df[\"3\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подсчитать, сколько раз встретилось в столбце '3' каждое уникальное значение\n",
    "df[\"3\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доступ к столбцу можно получить не только через квадратные скобки, но и через точку, по аналогии с атрибутом класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"hash\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот доступ к строкам можно получить при помощи `.iloc` и `loc`. Внешне они выглядят одинаково, но отличаются в деталях: первый индексирует по номеру строки, а второй — по индексирующему столбцу. Мы вернёмся к этому ниже, когда будет говорить про данные пассажиров Титаника. Обратите внимание, что такая индексация возвращает новый объект класса `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# склеить две таблицы по строкам\n",
    "df1 = df.iloc[:5]\n",
    "df2 = df.iloc[10:15]\n",
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# склеить две таблицы по столбцам\n",
    "df1 = df[[\"hash\", \"1\"]]\n",
    "df2 = df[[\"3\", \"4\"]]\n",
    "pd.concat([df1, df2], axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод `DataFrame.merge` объединяет таблицы по переданному столбцу (аналог SQL: JOIN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# таблица с оценками\n",
    "df_grades = pd.read_csv(\"grades.csv\", index_col=0)\n",
    "df_grades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hashes = pd.read_csv(\"hashes.csv\")\n",
    "df_hashes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не для всех студентов известны оценки!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grades.hash.nunique(), df_hashes.hash.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# присоединить подходящие строки из df_grades к df_hashes\n",
    "df = pd.merge(df_hashes, df_grades, on=\"hash\", how=\"left\")\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# присоединить подходящие строки из df_hashes к df_grades\n",
    "df = pd.merge(df_hashes, df_grades, on=\"hash\", how=\"right\")\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пересечение таблиц\n",
    "# в данном случае эквивалентно 'right', т.к. в df_grades нет таких хэшей, которые отсутствуют в df_hashes\n",
    "df = pd.merge(df_hashes, df_grades, on=\"hash\", how=\"inner\")\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединение таблиц\n",
    "# в данном случае эквивалентно 'left', т.к. в df_grades нет таких хэшей, которые отсутствуют в df_hashes\n",
    "df = pd.merge(df_hashes, df_grades, on=\"hash\", how=\"outer\")\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбрать из таблицы хэшей только те строки, в которых хэш есть в таблице оценок\n",
    "# т.е. отобрать тех студентов, которые писали контрольную и были оценены\n",
    "df = df_hashes[df_hashes.hash.isin(df_grades.hash)]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сколько человек из каждой группы были оценены?\n",
    "df.Группа.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[\"Группа\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод `DataFrame.groupby` делает группировку строк по значениям в каком-то столбце, чтобы мы могли их усреднить/просуммировать/etc. Например, если бы у нас была таблица вида [студент - предмет - оценка], то мы могли бы сгруппировать строки по столбцу предмета и посчитать по каждому предмету среднюю оценку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгруппировать строки по столбцу '1'\n",
    "gr = df_grades.groupby(by=\"1\")\n",
    "gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grades[\"1\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# какая средняя оценка (и ее дисперсия) за другие задачи у студентов, получивших конкретную оценку по задаче '1'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# дисперсия\n",
    "gr.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# откуда взялись NaN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.get_group(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Работаем с датасетом пассажиров Титаника\n",
    "\n",
    "[Cсылка на скачивание](https://disk.yandex.ru/i/GWBoeAFjSMeiLg)\n",
    "\n",
    "Каждая строчка наборов данных содержит следующие поля:\n",
    "\n",
    "- Pclass — класс пассажира (1 — высший, 2 — средний, 3 — низший);\n",
    "\n",
    "- Name — имя;\n",
    "\n",
    "- Sex — пол;\n",
    "\n",
    "- Age — возраст;\n",
    "\n",
    "- SibSp — количество братьев, сестер, сводных братьев, сводных сестер, супругов на борту Титаника;\n",
    "\n",
    "- Parch — количество родителей, детей (в том числе приемных) на борту Титаника;\n",
    "\n",
    "- Ticket — номер билета;\n",
    "\n",
    "- Fare — плата за проезд;\n",
    "\n",
    "- Cabin — каюта;\n",
    "\n",
    "- Embarked — порт посадки (C — Шербур; Q — Квинстаун; S — Саутгемптон)\n",
    "\n",
    "- Survived - пассажир выжил или нет.\n",
    "\n",
    "В поле Age приводится количество полных лет. Для детей меньше 1 года — дробное. Если возраст не известен точно, то указано примерное значение в формате xx.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"titanic_train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# типы данных\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сравним, сколько места занимает столбец\n",
    "df[\"SibSp\"].astype(\"int64\").memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SibSp\"].astype(\"int8\").memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для первичного анализа полезно посмотреть на базовые статистики численных переменных. Для этого есть готовый метод:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также полезно проверить, какие переменные коррелированы больше, а какие — меньше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[\"Survived\"]\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Survived\", \"Age\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление данных одного из столбцов\n",
    "X = df[df.columns.drop(\"Survived\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Survived\", axis=1)  # same thing as previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обещанная индексация! Давайте сперва проиндексируем таблицу двумя способами через `iloc` и `loc`, а затем изменим индексирующий столбец и посмотри на разницу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[[5, 8, 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[[5, 8, 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Меняем индексацию!\n",
    "df_new = df.set_index(\"Name\")\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.loc[\"Braund, Mr. Owen Harris\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df[\"Sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df[\"Name\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(\"PassengerId\", \"Sex\", \"Survived\", \"count\").plot(kind=\"bar\", stacked=True);\n",
    "# Какой вывод из полученных гистограмм?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(\"PassengerId\", \"Pclass\", \"Survived\", \"count\").plot(\n",
    "    kind=\"bar\", stacked=True\n",
    ");\n",
    "# Какой вывод из полученных гистограмм?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2)\n",
    "df.pivot_table(\"PassengerId\", [\"SibSp\"], \"Survived\", \"count\").plot(\n",
    "    ax=axes[0], title=\"SibSp\"\n",
    ")\n",
    "df.pivot_table(\"PassengerId\", [\"Parch\"], \"Survived\", \"count\").plot(\n",
    "    ax=axes[1], title=\"Parch\"\n",
    ");\n",
    "\n",
    "# Какой вывод из полученных графиков?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x=\"PassengerId\", y=\"Fare\", kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка и преобразование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем текстовый признак \"Пол\" в числовые значения\n",
    "df[\"DecodedSex\"] = df[\"Sex\"].map({\"male\": 1, \"female\": -1, \"unknown\": 0})\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# добавим еще одну характеристику для каждого объекта датасета\n",
    "def fun(age):\n",
    "    return age / 100\n",
    "\n",
    "\n",
    "df[\"NewAge\"] = df[\"Age\"].apply(fun)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# то же самое можно сделать с помощью лямбда функции\n",
    "df[\"NewAge\"] = df[\"Age\"].apply(lambda age: age / 100)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"NewAge\"] = df[\"Age\"] / 100\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важно!** Pandas, как и NumPy, является лишь обёрткой на питоне для вычислительно эффективных операций над большими данными. Любое использование циклов в pandas приводит к неэффективности кода. Методы `.apply` и `.map` **медленные**, потому что внутри в цикле применяют питоновскую функцию к элементам таблицы. Старайтесь всегда использовать более эффективные реализации (например, арифметические операторы над столбцами) и прибегать к `.apply` и `.map` только в крайнем случае!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "df[\"NewAge\"] = df[\"Age\"].apply(lambda age: age / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "df[\"NewAge\"] = df[\"Age\"] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выделим фамилию из данных\n",
    "df[\"Surname\"] = df[\"Name\"].apply(lambda name: name.split(\",\")[0])  # option1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Surname.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Surname\"] = df[\"Name\"].apply(lambda name: name[: name.find(\",\")])  # option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Surname\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values  # df -> numpy.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исследуем возраст пассажиров Титаника\n",
    "df.groupby(\"Sex\")[\"Age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# опять же, обращаем внимание на эффективное использование pandas\n",
    "%timeit df.groupby(\"Sex\")[\"Age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df.groupby(\"Sex\")[\"Age\"].apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Sex\")[\"Age\"].apply(lambda ages: np.mean(ages) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Survived\")[\"Age\"].apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# группировка по нескольким столбцам и агрегация нескольких полей сразу\n",
    "df.groupby([\"Sex\", \"Pclass\"]).agg(avg=(\"Age\", \"mean\"), avg_surv=(\"Survived\", \"mean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .mean -> .count\n",
    "# В скольких семьях было больше трёх человек?\n",
    "np.sum(df.groupby(\"Surname\")[\"Name\"].count() > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сколько семей, в которых минимальный возраст меньше 10 лет?\n",
    "np.sum(df.groupby(\"Surname\")[\"Age\"].apply(min) < 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова про индексацию! Как и в numpy, можно индексировать значения булевыми масками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((df[\"Age\"] > 10) & (df[\"Age\"] < 20)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пассажиры, удовлетворяющие условию\n",
    "df.loc[(df[\"Age\"] > 10) & (df[\"Age\"] < 20)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
